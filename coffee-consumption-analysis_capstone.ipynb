{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9414ec1",
   "metadata": {},
   "source": [
    "üìò Coffee Consumption Analysis ‚Äì Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406532d6",
   "metadata": {},
   "source": [
    "üíæ Installation\n",
    "\n",
    "Install the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18549cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sqlalchemy\n",
    "#pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c8a79",
   "metadata": {},
   "source": [
    "+ sqlalchemy is the high-level SQL toolkit and Object Relational Mapper (ORM) for Python.\n",
    "\n",
    "+ psycopg2-binary is the PostgreSQL database adapter required for sqlalchemy to connect to Postgres databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672015c",
   "metadata": {},
   "source": [
    "üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab66ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a05a0",
   "metadata": {},
   "source": [
    "### üìä Load FAO Coffee Supply Data\n",
    "\n",
    "This dataset from **[FAOSTAT](https://www.fao.org/faostat/en/#data/FBS)** covers **coffee supply (in kg/capita/year)** for **every country between 2010 and 2022**.  \n",
    "We'll use this data to understand national-level coffee consumption trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76da9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fao_df = pd.read_csv('data/FAOSTAT_data_en_7-24-2025.csv')\n",
    "#fao_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0030b72",
   "metadata": {},
   "source": [
    "### üß¨ Load NHANES Data\n",
    "\n",
    "NHANES (National Health and Nutrition Examination Survey) is a program by the **[U.S. CDC](https://wwwn.cdc.gov/nchs/nhanes/default.aspx)**.  \n",
    "It includes extensive health and dietary data collected in 2-year cycles.\n",
    "\n",
    "Each data file is named to reflect its cycle. For example:\n",
    "\n",
    "- `DEMO_C.XPT` ‚Üí 2003‚Äì2004  \n",
    "- `DEMO_G.XPT` ‚Üí 2011‚Äì2012\n",
    "\n",
    "You can refer to the suffix mapping table below to interpret the cycle:\n",
    "\n",
    "| Suffix | Cycle                |\n",
    "|--------|----------------------|\n",
    "| _A     | 1999‚Äì2000            |\n",
    "| _B     | 2001‚Äì2002            |\n",
    "| _C     | 2003‚Äì2004            |\n",
    "| _D     | 2005‚Äì2006            |\n",
    "| _E     | 2007‚Äì2008            |\n",
    "| _F     | 2009‚Äì2010            |\n",
    "| _G     | 2011‚Äì2012            |\n",
    "| _H     | 2013‚Äì2014            |\n",
    "| _I     | 2015‚Äì2016            |\n",
    "| _J     | 2017‚Äì2018            |\n",
    "| _K     | 2019‚Äì2020 *(not released)* |\n",
    "|P_     | 2017‚ÄìMar 2020 *(pre-pandemic)* |\n",
    "| _L     | 2021‚Äì2023            |\n",
    "\n",
    "Use the proper prefix (e.g., `P_`) for special cycles like 2017‚Äì2020 when loading files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7cf75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHANES cycle mapping\n",
    "cycles = {\n",
    "    '2009-2010': 'F',\n",
    "    '2011-2012': 'G',\n",
    "    '2013-2014': 'H',\n",
    "    '2015-2016': 'I',\n",
    "    '2017-2018': 'J',\n",
    "    '2017-2020': 'P',  # pre-pandemic cycle with 'P_' prefix and no suffix\n",
    "    '2021-2023': 'L'\n",
    "}\n",
    "\n",
    "def load_nhanes_file(cycle, suffix, file_prefix):\n",
    "    if suffix == 'P':\n",
    "        # Pre-pandemic files have 'P_' prefix and no suffix\n",
    "        file_path = f'./data/nhanes_raw/P_{file_prefix}.xpt'\n",
    "    else:\n",
    "        # Other files follow the standard format\n",
    "        file_path = f'./data/nhanes_raw/{file_prefix}_{suffix}.xpt'\n",
    "    df = pd.read_sas(file_path, format='xport', encoding='utf-8')\n",
    "    df['cycle'] = cycle\n",
    "    return df\n",
    "\n",
    "def load_all_cycles(base_prefix):\n",
    "    all_dfs = []\n",
    "    for cycle, suffix in cycles.items():\n",
    "        try:\n",
    "            df = load_nhanes_file(cycle, suffix, base_prefix)\n",
    "            all_dfs.append(df)\n",
    "        except FileNotFoundError:\n",
    "            if suffix == 'P':\n",
    "                print(f\"Missing file: P_{base_prefix}.xpt\")\n",
    "            else:\n",
    "                print(f\"Missing file: {base_prefix}_{suffix}.xpt\")\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Load all required datasets\n",
    "demo_all   = load_all_cycles('DEMO')\n",
    "bmx_all    = load_all_cycles('BMX')\n",
    "dr1tot_all = load_all_cycles('DR1TOT')\n",
    "dr1iff_all = load_all_cycles('DR1IFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a046e",
   "metadata": {},
   "source": [
    "‚òï Identify Coffee-Related Food Codes (FNDDS 2021‚Äì2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f94c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109 coffee-related food codes.\n",
      "[92100000, 92100500, 92101000, 92101500, 92101600]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/WWEIA_August2021_August2023_foodcat_FNDDS.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load specific sheet\n",
    "fndds = xl.parse(sheet_name='Aug2021-Aug2023_FNDDS_foodcat')\n",
    "\n",
    "# Filter rows with 'coffee'\n",
    "coffee_rows = fndds[fndds['category_description'].str.contains('coffee', case=False, na=False)]\n",
    "\n",
    "# Get food_code list\n",
    "coffee_codes = coffee_rows['food_code'].unique().tolist()\n",
    "\n",
    "print(f\"Found {len(coffee_codes)} coffee-related food codes.\")\n",
    "print(coffee_codes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b30589",
   "metadata": {},
   "source": [
    "üéØ Filter NHANES Dietary Data for Coffee Consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2885d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals who consumed coffee: 21054\n"
     ]
    }
   ],
   "source": [
    "# Filter individuals who consumed coffee\n",
    "coffee_consumers = dr1iff_all[dr1iff_all['DR1IFDCD'].isin(coffee_codes)]\n",
    "coffee_seqns = coffee_consumers['SEQN'].unique()\n",
    "\n",
    "print(f\"Number of individuals who consumed coffee: {len(coffee_seqns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215a33a",
   "metadata": {},
   "source": [
    "üßπ Subset All NHANES Tables for Coffee Consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89c20fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_caffeine = dr1tot_all[dr1tot_all['SEQN'].isin(coffee_seqns)]\n",
    "coffee_demo     = demo_all[demo_all['SEQN'].isin(coffee_seqns)]\n",
    "coffee_bmx      = bmx_all[bmx_all['SEQN'].isin(coffee_seqns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b274c14",
   "metadata": {},
   "source": [
    "üßº Clean and Deduplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26db07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_consumers_clean = coffee_consumers.drop_duplicates(subset=['SEQN'])\n",
    "coffee_consumers_clean_all = coffee_consumers.drop_duplicates(subset=['SEQN', 'DR1IFDCD'])\n",
    "\n",
    "coffee_caffeine_clean = coffee_caffeine.drop_duplicates(subset='SEQN')\n",
    "coffee_demo_clean     = coffee_demo.drop_duplicates(subset='SEQN')\n",
    "coffee_bmx_clean      = coffee_bmx.drop_duplicates(subset='SEQN')\n",
    "\n",
    "# Optional: Filter for specific variables (not shown here, uncomment if needed)\n",
    "# coffee_demo_clean = coffee_demo_clean[['SEQN', 'RIDAGEYR', ...]]\n",
    "# coffee_bmx_clean = coffee_bmx_clean[['SEQN', 'BMXBMI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced88cd",
   "metadata": {},
   "source": [
    "üóÑÔ∏è Export Cleaned Tables to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a897d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "config = dotenv_values()\n",
    "\n",
    "pg_user = config['POSTGRES_USER']\n",
    "pg_pass = config['POSTGRES_PASS']\n",
    "pg_host = config['POSTGRES_HOST']\n",
    "pg_port = config['POSTGRES_PORT']\n",
    "pg_db   = config['POSTGRES_DB']\n",
    "pg_schema = config['POSTGRES_SCHEMA']\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}\")\n",
    "\n",
    "# Set search_path (schema)\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f\"SET search_path TO {pg_schema}\"))\n",
    "\n",
    "# Export cleaned tables\n",
    "coffee_consumers_clean.to_sql('coffee_consumers', con=engine, if_exists='replace', index=False, schema=pg_schema)\n",
    "coffee_consumers_clean_all.to_sql('coffee_consumers_all', con=engine, if_exists='replace', index=False, schema=pg_schema)\n",
    "coffee_caffeine_clean.to_sql('coffee_caffeine', con=engine, if_exists='replace', index=False, schema=pg_schema)\n",
    "coffee_demo_clean.to_sql('coffee_demo', con=engine, if_exists='replace', index=False, schema=pg_schema)\n",
    "coffee_bmx_clean.to_sql('coffee_bmx', con=engine, if_exists='replace', index=False, schema=pg_schema)\n",
    "fao_df.to_sql('fao_coffee_supply', con=engine, if_exists='replace', index=False, schema=pg_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f933de1",
   "metadata": {},
   "source": [
    "‚úÖ Summary\n",
    "\n",
    "At this stage:\n",
    "\n",
    "+ FAO coffee supply data is loaded and stored.\n",
    "\n",
    "+ NHANES individuals who consumed coffee were identified.\n",
    "\n",
    "+ Key demographic, intake, and BMI data were extracted and cleaned.\n",
    "\n",
    "+ All processed data is saved to PostgreSQL for further analysis (e.g., in a dashboard or statistical modeling).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
